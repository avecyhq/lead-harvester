LeadHarvester – MVP PRD
Last updated: 2025-06-15

────────────────────────────────────────────────────────────────────────

0 Executive Summary
LeadHarvester is a SaaS tool that

Scrapes Google Maps (Serper.dev) for businesses by category × city × results-page

Runs a cost-optimised enrichment waterfall to obtain an owner name, a verified email, and social links

Stores all data in Supabase with Row-Level Security (RLS)

Lets users export CSV or sync to Meadowlark under a per-user credit model

────────────────────────────────────────────────────────────────────────

1 User Stories & Acceptance Tests
#1 Paste ≤ 25 cities, choose pages 1–3 → Form blocks > 25 lines; page check-boxes toggle
#2 View Scrape History row with city summary → Table shows “Austin + 24 more”; hover reveals list
#3 Open a batch and view leads with filters → Lead table renders; filter by confidence ≥ 0.9 & verified
#4 Export selected leads or sync to Meadowlark → CSV downloads; Meadowlark API returns 200
#5 Credits decrement (-1 enrichment, -1 verification) → Credit badge updates; actions block at 0

Note A – profiles.credits
Supabase profiles table must include credits integer and each enrichment / verification path decrements it atomically.

────────────────────────────────────────────────────────────────────────

2 Data Model (Supabase)

leads (table)
id uuid PK
user_id uuid
batch_id uuid FK→scrape_batches.id
business_name text
address text
city text
state text
website text
phone text
rating numeric
rating_count int
query_source text (e.g. “Austin – Page 2”)
page_number int (1/2/3)
owner_name text
owner_confidence numeric (0-1)
owner_reasoning text
owner_source text (“Kitt”, “DropContact”, “GPT-4o”, …)
email text
email_verified bool
linkedin_url text
facebook_url text
instagram_url text
enrichment_status text
sync_status text
created_at timestamptz default now()

scrape_batches (table)
id uuid PK
user_id uuid
category text
cities text[] (full list, ≤ 25)
pages int[] (e.g. {1,2,3})
total_leads int
created_at timestamptz

RLS: user_id = auth.uid() on both tables (insert / select / update / delete).

────────────────────────────────────────────────────────────────────────

3 Scraping Workflow

POST /api/scrape with category, cities[], pages[]

Loop city×page → Serper.dev → 10 listings

De-duplicate (domain OR phone OR name+address)

Insert lead stubs with enrichment_status='pending' and shared batch_id

Return batch_id for frontend progress polling

────────────────────────────────────────────────────────────────────────

4 Enrichment Waterfall (order & cost per hit)
A Pattern-guess email → MillionVerifier $0.0004
B Kitt.ai $0.0065
C Prospeo $0.006
D LinkedIn-finder (Kaspr / Skrapp / Apollo) $0.008 TODO: choose provider
E LeadMagic $0.011
F DropContact $0.05
G enrichOwnerFromDomain (GPT-4o / Claude) $0.001
H Firecrawl website crawl $0.005

Stop when a lead has
owner_name AND email_verified = true AND owner_confidence ≥ 0.90
Finally re-verify all collected emails via MillionVerifier bulk pass.

────────────────────────────────────────────────────────────────────────

5 Key Code Modules
/lib/serper.ts fetchMapsResults(city, category, page)
/lib/enrich/owner.ts enrichOwnerFromDomain(domain) – GPT agent
/lib/enrich/waterfall.ts orchestrates stages A → H
/app/api/scrape/route.ts triggers scrape & queues enrichment
/app/api/enrich/route.ts worker endpoint / queue consumer
/app/api/sync/meadowlark.ts STUB for Meadowlark sync (MVP)

Note B – Meadowlark Stub
Provide stub implementation returning 200; swap real credentials post-MVP.

────────────────────────────────────────────────────────────────────────

6 Frontend UX

6.1 Scrape Form
• Category input • Multiline city textarea (live count) • Page check-boxes 1 2 3 • Credit badge

6.2 Scrape History table
Category | Cities (Austin + 24 more, hover shows all) | Pages | Leads | Date | Actions

6.3 Lead Table
Columns: business | owner | email | city | confidence | verified | source
Row expand → reasoning JSON + steps
Bulk actions: Export CSV, Sync to Meadowlark, Re-enrich, Delete

────────────────────────────────────────────────────────────────────────

7 Credit Logic
Action Credits −
Email enrichment success 1
Email verification 1
All decrements via stored procedure rpc_deduct_credits() to avoid race conditions.

────────────────────────────────────────────────────────────────────────

8 Environment Variables
SERPER_API_KEY, KITT_API_KEY, PROSPEO_API_KEY,
KASPR_API_KEY / SKRAPP_API_KEY / APOLLO_API_KEY,
LEADMAGIC_TOKEN, DROPCONTACT_API_KEY,
OPENAI_API_KEY (for GPT-4o), FIRECRAWL_API_KEY, MV_API_KEY,
MEADOWLARK_API_KEY

────────────────────────────────────────────────────────────────────────

9 Non-Goals (MVP)
• Automated billing / Stripe
• Team (multi-seat) accounts
• Advanced analytics dashboard
• Internationalisation (i18n)

────────────────────────────────────────────────────────────────────────

10 Exit Criteria

End-to-end run yields ≥ 90 % of leads with verified email and owner_confidence ≥ 0.90

Blended variable cost ≤ $0.01 per verified lead (1 k scale)

All DB CRUD blocked by RLS outside owner’s user_id

Note C – Waterfall TODOs
If a provider (Kaspr / Skrapp / Apollo) is not yet integrated, leave // TODO in code; not a PRD defect.

Note D – RLS double-check
Before launch, run Supabase RLS tester to confirm batch & lead rows cannot be accessed by other users.

────────────────────────────────────────────────────────────────────────

END OF PRD